{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20f129b-fd80-4684-bd95-6fed1b7298b0",
   "metadata": {},
   "source": [
    "To be saved as a .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c3dfb-fe2b-4957-a221-e9a4cf0b9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data_prep.py\n",
    "Preprocess cycling race datasets to build a feature table for a Tour‑de‑France prediction model.\n",
    "\n",
    "Public API\n",
    "----------\n",
    "preprocess_tdf_data(folder_path: str, output_path: str | None = None) -> pd.DataFrame\n",
    "\n",
    "Usage example\n",
    "-------------\n",
    ">>> from data_prep import preprocess_tdf_data\n",
    ">>> df = preprocess_tdf_data(r\"D:/Data/Cycling/TDF_Predictor\", \"tdf_prepared_2011_2024.csv\")\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# I/O helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _load_raw(folder_path: str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Read every raw CSV file required for feature engineering.\"\"\"\n",
    "\n",
    "    join = os.path.join\n",
    "    return {\n",
    "        \"uwt_res\": pd.read_csv(\n",
    "            join(folder_path, \"UWT_Race_Results.csv\"),\n",
    "            usecols=[\"Pos\", \"Born\", \"Rider URL\", \"YEAR\", \"RACE\", \"RACE_URL\"],\n",
    "        ),\n",
    "        \"uwt_races\": pd.read_csv(join(folder_path, \"UWT_Races_2011_2024.csv\")),\n",
    "        \"pt_res\": pd.read_csv(\n",
    "            join(folder_path, \"PT_Race_Results.csv\"),\n",
    "            usecols=[\"Pos\", \"Born\", \"Rider URL\", \"YEAR\", \"RACE\", \"RACE_URL\"],\n",
    "        ),\n",
    "        \"pt_races\": pd.read_csv(join(folder_path, \"PT_Races_2011_2024.csv\")),\n",
    "        \"fc_rank\": pd.read_csv(\n",
    "            join(folder_path, \"fc_rankings_2002_2024.csv\"),\n",
    "            usecols=[\"rider_id\", \"Rider\", \"Year\", \"Points\"],\n",
    "        ),\n",
    "        \"gt_history\": pd.read_csv(join(folder_path, \"GT_History.csv\")),\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Grand‑Tour feature engineering\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _prepare_gt_history(gt_history: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return GT‑specific yearly features for Tour‑de‑France participants.\"\"\"\n",
    "\n",
    "    gt_history = gt_history.copy()\n",
    "    gt_history[\"Pos_clean\"] = pd.to_numeric(gt_history[\"Pos\"], errors=\"coerce\")\n",
    "\n",
    "    def _race_order(row) -> int:\n",
    "        if row[\"Year\"] == 2020:  # pandemic‑shifted calendar\n",
    "            mapping = {\"Tour de France\": 1, \"Giro d'Italia\": 2, \"Vuelta a España\": 3}\n",
    "        else:\n",
    "            mapping = {\"Giro d'Italia\": 1, \"Tour de France\": 2, \"Vuelta a España\": 3}\n",
    "        return mapping.get(row[\"Race\"], 99)\n",
    "\n",
    "    gt_history[\"race_order\"] = gt_history.apply(_race_order, axis=1)\n",
    "    gt_history.sort_values([\"rider_id\", \"Year\", \"race_order\"], inplace=True)\n",
    "\n",
    "    # initialise engineered columns\n",
    "    for col in [\n",
    "        \"best_tdf_result\",\n",
    "        \"best_other_gt_result\",\n",
    "        \"best_recent_tdf_result\",\n",
    "        \"best_recent_other_gt_result\",\n",
    "        \"tdf_debut\",\n",
    "        \"gt_debut\",\n",
    "        \"rode_giro\",\n",
    "    ]:\n",
    "        gt_history[col] = np.nan\n",
    "\n",
    "    processed_rows: list[pd.DataFrame] = []\n",
    "\n",
    "    for _, rider_df in gt_history.groupby(\"rider_id\"):\n",
    "        rider_df = rider_df.copy()\n",
    "        best_tdf: float | int | np.nan = np.nan\n",
    "        best_other: float | int | np.nan = np.nan\n",
    "        seen_gt = False\n",
    "        seen_tdf = False\n",
    "\n",
    "        for idx, row in rider_df.iterrows():\n",
    "            year, race, pos = row[\"Year\"], row[\"Race\"], row[\"Pos_clean\"]\n",
    "\n",
    "            # first‑ever GT / TdF flags\n",
    "            if not seen_gt:\n",
    "                rider_df.at[idx, \"gt_debut\"] = 1\n",
    "                seen_gt = True\n",
    "            if race == \"Tour de France\" and not seen_tdf:\n",
    "                rider_df.at[idx, \"tdf_debut\"] = 1\n",
    "                seen_tdf = True\n",
    "\n",
    "            # career bests so far\n",
    "            rider_df.at[idx, \"best_tdf_result\"] = best_tdf\n",
    "            rider_df.at[idx, \"best_other_gt_result\"] = best_other\n",
    "\n",
    "            # recent three‑year window bests\n",
    "            recent = rider_df[(rider_df[\"Year\"] < year) & (rider_df[\"Year\"] >= year - 3)]\n",
    "            rider_df.at[idx, \"best_recent_tdf_result\"] = recent.loc[\n",
    "                recent[\"Race\"] == \"Tour de France\", \"Pos_clean\"\n",
    "            ].min()\n",
    "            rider_df.at[idx, \"best_recent_other_gt_result\"] = recent.loc[\n",
    "                recent[\"Race\"].isin([\"Giro d'Italia\", \"Vuelta a España\"]), \"Pos_clean\"\n",
    "            ].min()\n",
    "\n",
    "            # rode Giro earlier in season?\n",
    "            if race == \"Tour de France\":\n",
    "                if year == 2020:\n",
    "                    rider_df.at[idx, \"rode_giro\"] = 0  # chronological anomaly\n",
    "                else:\n",
    "                    rode_giro = rider_df[\n",
    "                        (rider_df[\"Year\"] == year)\n",
    "                        & (rider_df[\"Race\"] == \"Giro d'Italia\")\n",
    "                        & (rider_df[\"race_order\"] < row[\"race_order\"])\n",
    "                    ]\n",
    "                    rider_df.at[idx, \"rode_giro\"] = 0 if rode_giro.empty else 1\n",
    "\n",
    "            # update all‑time bests *after* current race\n",
    "            if not np.isnan(pos):\n",
    "                if race == \"Tour de France\":\n",
    "                    best_tdf = pos if np.isnan(best_tdf) else min(best_tdf, pos)\n",
    "                else:\n",
    "                    best_other = pos if np.isnan(best_other) else min(best_other, pos)\n",
    "\n",
    "        processed_rows.append(rider_df)\n",
    "\n",
    "    best_gt = (\n",
    "        pd.concat(processed_rows)\n",
    "        .query(\"Race == 'Tour de France'\")\n",
    "        .sort_values([\"rider_id\", \"Year\", \"race_order\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return best_gt[\n",
    "        [\n",
    "            \"rider_id\",\n",
    "            \"Year\",\n",
    "            \"best_tdf_result\",\n",
    "            \"best_other_gt_result\",\n",
    "            \"best_recent_tdf_result\",\n",
    "            \"best_recent_other_gt_result\",\n",
    "            \"tdf_debut\",\n",
    "            \"gt_debut\",\n",
    "            \"rode_giro\",\n",
    "        ]\n",
    "    ].rename(columns={\"rider_id\": \"Rider_ID\"})\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Race‑results / ranking feature engineering\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _prepare_race_tables(data: dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Create per‑rider, per‑year performance summary (incl. Year‑Before stats).\"\"\"\n",
    "\n",
    "    # combine WorldTour & ProTour stage‑race results\n",
    "    uwt_res, pt_res = data[\"uwt_res\"].copy(), data[\"pt_res\"].copy()\n",
    "    uwt_res[\"CAT\"], pt_res[\"CAT\"] = \"2.UWT\", \"2.Pro\"\n",
    "    res = pd.concat([uwt_res, pt_res], ignore_index=True)\n",
    "\n",
    "    res[\"Year\"] = res[\"YEAR\"].astype(int)\n",
    "    res[\"Rider_ID\"] = res[\"Rider URL\"].str.extract(r\"r=(\\d+)\").astype(int)\n",
    "    res[\"Race_ID\"] = res[\"RACE_URL\"].str.extract(r\"r=(\\d+)\").astype(int)\n",
    "    res = res[[\"Year\", \"Race_ID\", \"CAT\", \"RACE\", \"Rider_ID\", \"Born\", \"Pos\"]]\n",
    "\n",
    "    # ---------- race metadata (calendar position) ----------\n",
    "    races = pd.concat([data[\"uwt_races\"], data[\"pt_races\"]])\n",
    "    races = races[races[\"CAT\"].isin([\"2.UWT\", \"2.HC\", \"2.Pro\"])].copy()\n",
    "    races[\"Race_ID\"] = races[\"RACE_URL\"].str.extract(r\"r=(\\d+)\").astype(int)\n",
    "    races.rename(columns={\"YEAR\": \"Year\", \"DATE\": \"Date\"}, inplace=True)\n",
    "    races = races[[\"Year\", \"Date\", \"Race_ID\"]]\n",
    "\n",
    "    # parse dd.mm‑dd.mm format -> start date\n",
    "    races[\"Start_Date\"] = pd.to_datetime(\n",
    "        races[\"Date\"].str.split(\"-\").str[0] + \".\" + races[\"Year\"].astype(str),\n",
    "        format=\"%d.%m.%Y\",\n",
    "    )\n",
    "    tdf_dates = races.loc[races[\"Race_ID\"] == 17, [\"Year\", \"Start_Date\"]].rename(\n",
    "        columns={\"Start_Date\": \"Tour_Date\"}\n",
    "    )\n",
    "    races = races.merge(tdf_dates, on=\"Year\", how=\"left\")\n",
    "    races[\"Before_Tour\"] = (races[\"Start_Date\"] < races[\"Tour_Date\"]).astype(int)\n",
    "    races.drop(columns=[\"Date\", \"Start_Date\", \"Tour_Date\"], inplace=True)\n",
    "\n",
    "    # ---------- FirstCycling rankings ----------\n",
    "    fc_rank = data[\"fc_rank\"].copy()\n",
    "    fc_rank[\"Year\"] = fc_rank[\"Year\"].astype(int)\n",
    "    fc_rank[\"Rider_ID\"] = fc_rank[\"rider_id\"].astype(int)\n",
    "    fc_rank = fc_rank.drop(columns=[\"Rider\"]).drop_duplicates()\n",
    "\n",
    "    # ---------- merge results with metadata & rankings ----------\n",
    "    res_races = res.merge(races, on=[\"Year\", \"Race_ID\"], how=\"left\")\n",
    "    res_races_fc = res_races.merge(\n",
    "        fc_rank, on=[\"Rider_ID\", \"Year\"], how=\"left\", validate=\"m:1\"\n",
    "    ).rename(columns={\"Points\": \"FC_Points\"})\n",
    "\n",
    "    # clean Pos -> int placeholders\n",
    "    res_races_fc[\"Pos\"] = (\n",
    "        res_races_fc[\"Pos\"]\n",
    "        .replace({\"DNF\": 999, \"DNS\": 998, \"DSQ\": 997})\n",
    "        .fillna(1000)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    res_races_fc[\"TDF_Pos\"] = np.where(res_races_fc[\"Race_ID\"] == 17, res_races_fc[\"Pos\"], 1000)\n",
    "    res_races_fc[\"FC_Points\"] = res_races_fc[\"FC_Points\"].fillna(0)\n",
    "    res_races_fc[\"FC_Pos\"] = (\n",
    "        res_races_fc.groupby(\"Year\")[\"FC_Points\"].rank(ascending=False, method=\"dense\").astype(int)\n",
    "    )\n",
    "\n",
    "    # convenience helper to mark best positions --------------------------------\n",
    "    def _best(col: str, before: bool, cat: str):\n",
    "        mask = (res_races_fc[\"Before_Tour\"] == (1 if before else 0)) & (\n",
    "            res_races_fc[\"CAT\"] == cat\n",
    "        )\n",
    "        if not before:\n",
    "            mask &= res_races_fc[\"Race_ID\"] != 17\n",
    "        res_races_fc[col] = np.where(mask, res_races_fc[\"Pos\"], np.nan)\n",
    "\n",
    "    _best(\"Best_Pos_BT_UWT\", before=True, cat=\"2.UWT\")\n",
    "    _best(\"Best_Pos_BT_PT\", before=True, cat=\"2.Pro\")\n",
    "    _best(\"Best_Pos_AT_UWT\", before=False, cat=\"2.UWT\")\n",
    "    _best(\"Best_Pos_AT_PT\", before=False, cat=\"2.Pro\")\n",
    "\n",
    "    # aggregate to rider‑year level -------------------------------------------\n",
    "    agg = res_races_fc.groupby([\"Rider_ID\", \"Year\", \"Born\"], as_index=False).agg(\n",
    "        FC_Points=(\"FC_Points\", \"max\"),\n",
    "        FC_Pos=(\"FC_Pos\", \"max\"),\n",
    "        Best_Pos_BT_UWT=(\"Best_Pos_BT_UWT\", \"min\"),\n",
    "        Best_Pos_BT_PT=(\"Best_Pos_BT_PT\", \"min\"),\n",
    "        Best_Pos_AT_UWT=(\"Best_Pos_AT_UWT\", \"min\"),\n",
    "        Best_Pos_AT_PT=(\"Best_Pos_AT_PT\", \"min\"),\n",
    "        TDF_Pos=(\"TDF_Pos\", \"min\"),\n",
    "    )\n",
    "\n",
    "    agg[\"Best_Pos_UWT\"] = agg[[\"Best_Pos_BT_UWT\", \"Best_Pos_AT_UWT\"]].min(axis=1)\n",
    "    agg[\"Best_Pos_PT\"] = agg[[\"Best_Pos_BT_PT\", \"Best_Pos_AT_PT\"]].min(axis=1)\n",
    "\n",
    "    # Year‑Before table --------------------------------------------------------\n",
    "    yb = agg.drop(columns=[\"FC_Pos\"]).copy()\n",
    "    yb[\"Year\"] += 1  # shift forward\n",
    "    yb = yb.rename(\n",
    "        columns={\n",
    "            \"FC_Points\": \"FC_Points_YB\",\n",
    "            \"Best_Pos_BT_UWT\": \"Best_Pos_BT_UWT_YB\",\n",
    "            \"Best_Pos_BT_PT\": \"Best_Pos_BT_PT_YB\",\n",
    "            \"Best_Pos_AT_UWT\": \"Best_Pos_AT_UWT_YB\",\n",
    "            \"Best_Pos_AT_PT\": \"Best_Pos_AT_PT_YB\",\n",
    "            \"Best_Pos_UWT\": \"Best_Pos_UWT_YB\",\n",
    "            \"Best_Pos_PT\": \"Best_Pos_PT_YB\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    full = agg.merge(\n",
    "        yb[\n",
    "            [\n",
    "                \"Rider_ID\",\n",
    "                \"Year\",\n",
    "                \"FC_Points_YB\",\n",
    "                \"Best_Pos_BT_UWT_YB\",\n",
    "                \"Best_Pos_BT_PT_YB\",\n",
    "                \"Best_Pos_AT_UWT_YB\",\n",
    "                \"Best_Pos_AT_PT_YB\",\n",
    "                \"Best_Pos_UWT_YB\",\n",
    "                \"Best_Pos_PT_YB\",\n",
    "            ]\n",
    "        ],\n",
    "        on=[\"Rider_ID\", \"Year\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    full[\"FC_Points_YB\"] = full[\"FC_Points_YB\"].fillna(0)\n",
    "    full[\"FC_Pos_YB\"] = (\n",
    "        full.groupby(\"Year\")[\"FC_Points_YB\"].rank(ascending=False, method=\"dense\").astype(int)\n",
    "    )\n",
    "\n",
    "    return full\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Top‑level pipeline function\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def preprocess_tdf_data(folder_path: str, output_path: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Run the complete preprocessing pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Directory containing all raw CSVs.\n",
    "    output_path : str | None, default=None\n",
    "        If provided, the resulting CSV will be written to this path. If the\n",
    "        path is relative, it is considered relative to *folder_path*.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The final feature table ready for model training.\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = str(folder_path)\n",
    "    data = _load_raw(folder_path)\n",
    "\n",
    "    race_table = _prepare_race_tables(data)\n",
    "    gt_table = _prepare_gt_history(data[\"gt_history\"])\n",
    "\n",
    "    df = race_table.merge(gt_table, on=[\"Rider_ID\", \"Year\"], how=\"left\")\n",
    "\n",
    "    # final tidy‑up -----------------------------------------------------------\n",
    "    df[\"Age\"] = df[\"Year\"] - df[\"Born\"]\n",
    "    df.drop(columns=[\"Born\"], inplace=True)\n",
    "\n",
    "    # convert placeholder ints back to categorical strings where needed\n",
    "    def _replace(series: pd.Series) -> pd.Series:\n",
    "        return series.replace({1000: np.nan, 999: \"DNF\", 998: \"DNS\", 997: \"DSQ\"})\n",
    "\n",
    "    df[\"TDF_Pos\"] = _replace(df[\"TDF_Pos\"])\n",
    "    for col in [\n",
    "        \"Best_Pos_BT_UWT\",\n",
    "        \"Best_Pos_AT_UWT_YB\",\n",
    "        \"Best_Pos_UWT_YB\",\n",
    "        \"Best_Pos_BT_PT\",\n",
    "        \"Best_Pos_AT_PT_YB\",\n",
    "        \"Best_Pos_PT_YB\",\n",
    "    ]:\n",
    "        df[col] = df[col].replace({999: \"DNF\"})\n",
    "\n",
    "    # reorder columns for readability ----------------------------------------\n",
    "    col_order = [\n",
    "        \"Rider_ID\",\n",
    "        \"Year\",\n",
    "        \"Age\",\n",
    "        \"TDF_Pos\",\n",
    "        \"Best_Pos_BT_UWT\",\n",
    "        \"Best_Pos_BT_PT\",\n",
    "        \"Best_Pos_AT_UWT_YB\",\n",
    "        \"Best_Pos_AT_PT_YB\",\n",
    "        \"Best_Pos_UWT_YB\",\n",
    "        \"Best_Pos_PT_YB\",\n",
    "        \"FC_Points_YB\",\n",
    "        \"FC_Pos_YB\",\n",
    "        \"best_tdf_result\",\n",
    "        \"best_other_gt_result\",\n",
    "        \"best_recent_tdf_result\",\n",
    "        \"best_recent_other_gt_result\",\n",
    "        \"tdf_debut\",\n",
    "        \"gt_debut\",\n",
    "        \"rode_giro\",\n",
    "    ]\n",
    "    remaining = [c for c in df.columns if c not in col_order]\n",
    "    df = df[col_order + remaining]\n",
    "\n",
    "    # write CSV if requested --------------------------------------------------\n",
    "    if output_path:\n",
    "        out_path = Path(output_path)\n",
    "        if not out_path.is_absolute():\n",
    "            out_path = Path(folder_path) / out_path\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f\"Wrote prepared data to {out_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CLI convenience\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Preprocess TdF datasets into feature table\")\n",
    "    parser.add_argument(\"folder\", help=\"Folder containing raw CSV files\")\n",
    "    parser.add_argument(\"-o\", \"--output\", help=\"Optional output CSV filename\", default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    preprocess_tdf_data(args.folder, args.output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
