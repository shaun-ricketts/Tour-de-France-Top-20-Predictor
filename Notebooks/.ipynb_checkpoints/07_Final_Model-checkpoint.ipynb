{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_Final_Model.ipynb\n",
    "\n",
    "This notebook loads the best model from hyperparameter tuning, optionally evaluates it on the test set, and saves the final model to disk for future use or deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Folder Path and Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root(start: Path, anchor_dirs=(\"src\", \"Data\")) -> Path:\n",
    "    \"\"\"\n",
    "    Walk up the directory tree until we find a folder that\n",
    "    contains all anchor_dirs (e.g. 'src' and 'Data').\n",
    "    \"\"\"\n",
    "    path = start.resolve()\n",
    "    for parent in [path] + list(path.parents):\n",
    "        if all((parent / d).is_dir() for d in anchor_dirs):\n",
    "            return parent\n",
    "    raise FileNotFoundError(\"Could not locate project root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data folder: C:\\Users\\Shaun Ricketts\\Documents\\Projects\\Cycling\\Tour de France Predictor - 2025\\Data\\Raw\n"
     ]
    }
   ],
   "source": [
    "# Locate the project root regardless of notebook depth\n",
    "project_root = find_project_root(Path.cwd())\n",
    "\n",
    "# ----- Code modules --------------------------------------------------\n",
    "src_path = project_root / \"src\" / \"top20_likelihood\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from data_prep import preprocess_tdf_data   # import data preproc function\n",
    "\n",
    "# ----- Data ----------------------------------------------------------\n",
    "data_path = project_root / \"Data\" / \"Processed\"\n",
    "print(\"Raw data folder:\", data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go up two levels to reach the project root\n",
    "project_root = Path.cwd().parents[1]\n",
    "src_path = project_root / 'src' / 'top20_likelihood'\n",
    "\n",
    "# Add to sys.path if not already there\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Now you can import your function\n",
    "from data_prep import preprocess_tdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race metadata\n",
    "df = pd.read_csv(data_path / \"tdf_prepared_2011_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import missing_value_handler\n",
    "from missing_value_handler import FillWithSentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = FillWithSentinel()\n",
    "df = cleaner.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out DNF or DSQ from TDF_Pos\n",
    "df = df[~df['TDF_Pos'].isin(['DNF', 'DSQ'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['TDF_Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TDF_Pos to numeric\n",
    "df['TDF_Pos'] = pd.to_numeric(df['TDF_Pos'])\n",
    "\n",
    "# 1 if TDF_Pos <= 20, else 0\n",
    "df['is_top20'] = (df['TDF_Pos'] <= 20).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date range for 2015+, and exclude 2020 & 2021\n",
    "df = df[(df['Year'] >= 2015) & (~df['Year'].isin([2020, 2021]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Best_Pos_BT_UWT', 'Best_Pos_BT_PT',\n",
    "            'FC_Pos_YB', 'best_recent_tdf_result',\n",
    "            'best_recent_other_gt_result', 'rode_giro']\n",
    "\n",
    "train_mask = (df['Year'] <= 2023)\n",
    "test_mask  = (df['Year'] == 2024)\n",
    "\n",
    "X_train = df.loc[train_mask, features]\n",
    "y_train = df.loc[train_mask, 'is_top20']\n",
    "X_test  = df.loc[test_mask, features]\n",
    "y_test  = df.loc[test_mask, 'is_top20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = project_root / \"Models\" / \"top20_likelihood\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from GridSearchCV (already trained and saved)\n",
    "model = joblib.load(model_dir / \"final_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       121\n",
      "           1       0.74      0.70      0.72        20\n",
      "\n",
      "    accuracy                           0.92       141\n",
      "   macro avg       0.84      0.83      0.84       141\n",
      "weighted avg       0.92      0.92      0.92       141\n",
      "\n",
      "ROC AUC: 0.9599173553719008\n",
      "Confusion Matrix:\n",
      " [[116   5]\n",
      " [  6  14]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "(project_root / \"Data\" / \"Processed\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to: C:\\Users\\Shaun Ricketts\\Documents\\Projects\\Cycling\\Tour de France Predictor - 2025\\Models\\top20_likelihood\\final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, model_dir / \"final_model.pkl\")\n",
    "print(f\"Final model saved to: {model_dir / 'final_model.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[test_mask, 'predicted_top20_proba'] = y_proba\n",
    "df.loc[test_mask, 'predicted_top20'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_root / \"Data\" / \"Processed\" / \"2024_predictions.csv\"\n",
    "df.loc[test_mask].to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The final model has been saved for deployment or further use. It was selected after careful hyperparameter tuning and evaluation. Future work may involve testing the model on new race editions or extending the feature set.\n",
    "\n",
    "Model path: `Models/top20_likelihood/final_model.pkl`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
