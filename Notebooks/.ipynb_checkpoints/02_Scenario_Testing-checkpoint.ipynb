{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Testing\n",
    "Tour de France Predictor - 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# visualisation tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn - Core Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# sklearn - Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Folder Path and Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root(start: Path, anchor_dirs=(\"src\", \"Data\")) -> Path:\n",
    "    \"\"\"\n",
    "    Walk up the directory tree until we find a folder that\n",
    "    contains all anchor_dirs (e.g. 'src' and 'Data').\n",
    "    \"\"\"\n",
    "    path = start.resolve()\n",
    "    for parent in [path] + list(path.parents):\n",
    "        if all((parent / d).is_dir() for d in anchor_dirs):\n",
    "            return parent\n",
    "    raise FileNotFoundError(\"Could not locate project root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data folder: C:\\Users\\Shaun Ricketts\\Documents\\Projects\\Cycling\\Tour de France Predictor - 2025\\Data\\Raw\n"
     ]
    }
   ],
   "source": [
    "# Locate the project root regardless of notebook depth\n",
    "project_root = find_project_root(Path.cwd())\n",
    "\n",
    "# ----- Code modules --------------------------------------------------\n",
    "src_path = project_root / \"src\" / \"top20_likelihood\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import preprocess_tdf_data   # import data preproc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Data ----------------------------------------------------------\n",
    "data_raw_path = project_root / \"Data\" / \"Raw\"\n",
    "print(\"Raw data folder:\", data_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = pd.read_csv(data_raw_path / \"tdf_prepared_2011_2024.csv\",\n",
    "                         usecols = ['Rider_ID', 'Year', 'Age', 'TDF_Pos', 'Best_Pos_BT_UWT',\n",
    "                           'Best_Pos_BT_PT', 'Best_Pos_UWT_YB', 'Best_Pos_PT_YB', 'FC_Pos_YB', 'best_recent_tdf_result', \n",
    "                           'best_recent_other_gt_result', 'rode_giro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Nulls and DNFs (etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 1: Replace DNFs with Nulls\n",
    "- Scenario 2: Replace DNFs and Nulls with Sentinel (999)\n",
    "- Scenario 3: Replace DNFs with Sentinel and leave Nulls\n",
    "- Scenario 4: Replace nulls/DNFs in Best_UWT results with Best_PT results (with weight), if still null use sentinel\n",
    "- Scenario 5: Replace nulls/DNFs in Best_UWT & Best_PT with previous year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a value for the sentinel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down columns to only ones likely to use in final model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cols with \"DNF\" value (\"DNS\" in same col as \"DNF\")\n",
    "dnf_columns = (prepared_df == \"DNF\").any()[lambda x: x].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cols with nulls\n",
    "null_columns = (prepared_df.isnull()).any()[lambda x: x].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"DNF\" with null and create _null indicator columns\n",
    "for col in dnf_columns:\n",
    "    prepared_df[col + \"_null\"] = prepared_df[col].replace(\"DNF\", np.nan)\n",
    "    prepared_df[col + \"_null\"] = prepared_df[col + \"_null\"].replace(\"DSQ\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List for outputted cols\n",
    "null_columns_list = [\n",
    " 'Best_Pos_BT_UWT_null',\n",
    " 'Best_Pos_BT_PT_null',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in null_columns:\n",
    "    prepared_df[col + \"_sent\"] = prepared_df[col].replace({\"DNF\": np.nan, \"DSQ\": np.nan})\n",
    "    prepared_df[col + '_sent_flag'] = prepared_df[col].isnull().astype(int)\n",
    "    prepared_df[col + '_sent'] = prepared_df[col + \"_sent\"].fillna(sentinel)\n",
    "    prepared_df[col + '_sent'] = prepared_df[col + '_sent'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_columns_list = [col for col in prepared_df.columns if col.endswith(\"_sent\")]\n",
    "sent_flag_columns_list = [col for col in prepared_df.columns if col.endswith(\"_sent_flag\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_columns_list = [\n",
    " 'Best_Pos_BT_UWT_sent',\n",
    " 'Best_Pos_BT_PT_sent',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_flag_columns_list = [\n",
    " 'Best_Pos_BT_UWT_sent_flag',\n",
    " 'Best_Pos_BT_PT_sent_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in dnf_columns:\n",
    "    prepared_df[col + \"_dnf_flag\"] = prepared_df[col].isin([\"DNF\", \"DSQ\"]).astype(int)  # Boolean indicator\n",
    "    prepared_df[col + \"_dnf_sent\"] = prepared_df[col].replace({\"DNF\": sentinel, \"DSQ\": sentinel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_flag_columns_list = [col for col in prepared_df.columns if col.endswith(\"_dnf_flag\")]\n",
    "dnf_sent_columns_list = [col for col in prepared_df.columns if col.endswith(\"_dnf_sent\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_sent_columns_list = [\n",
    " 'Best_Pos_BT_UWT_dnf_sent',\n",
    " 'Best_Pos_BT_PT_dnf_sent',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_flag_columns_list = [\n",
    " 'Best_Pos_BT_UWT_dnf_flag',\n",
    " 'Best_Pos_BT_PT_dnf_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a weight for use of pro-tour result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_weight_add = 3\n",
    "pt_weight_mult = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filled_from_pt_cols(df, pt_weight_add=3, pt_weight_mult=1.5):\n",
    "    uwt_pt_pairs = [\n",
    "        (\"Best_Pos_BT_UWT\", \"Best_Pos_BT_PT\"),\n",
    "        # add more if needed\n",
    "    ]\n",
    "    \n",
    "    filled_cols = []\n",
    "    flag_cols = []\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for uwt_col, pt_col in uwt_pt_pairs:\n",
    "        def fill_with_pt(row):\n",
    "            val = row[uwt_col]\n",
    "            pt_val = row[pt_col]\n",
    "\n",
    "            if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "                if pd.notna(pt_val) and pt_val not in [\"DNF\", \"DSQ\"]:\n",
    "                    try:\n",
    "                        return (float(pt_val) + pt_weight_add) * pt_weight_mult\n",
    "                    except:\n",
    "                        return 999  # sentinel\n",
    "                else:\n",
    "                    return 999\n",
    "            else:\n",
    "                try:\n",
    "                    return float(val)\n",
    "                except:\n",
    "                    return 999\n",
    "\n",
    "        filled_col_name = f\"{uwt_col}_filled_from_pt_add{pt_weight_add}_mult{pt_weight_mult}\"\n",
    "        flag_col_name = f\"{filled_col_name}_flag\"\n",
    "\n",
    "        df[filled_col_name] = df.apply(fill_with_pt, axis=1)\n",
    "        df[flag_col_name] = (df[filled_col_name] == 999).astype(int)\n",
    "\n",
    "        filled_cols.append(filled_col_name)\n",
    "        flag_cols.append(flag_col_name)\n",
    "\n",
    "    return df, filled_cols, flag_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uwt_pt_pairs = [\n",
    "    (\"Best_Pos_BT_UWT\", \"Best_Pos_BT_PT\"),\n",
    "    #(\"Best_Pos_AT_UWT_YB\", \"Best_Pos_AT_PT_YB\"),\n",
    "    #(\"Best_Pos_UWT_YB\", \"Best_Pos_PT_YB\"),\n",
    "]\n",
    "\n",
    "for uwt_col, pt_col in uwt_pt_pairs:\n",
    "    def fill_with_pt(row):\n",
    "        val = row[uwt_col]\n",
    "        pt_val = row[pt_col]\n",
    "\n",
    "        if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "            if pd.notna(pt_val) and pt_val not in [\"DNF\", \"DSQ\"]:\n",
    "                try:\n",
    "                    return (float(pt_val) + pt_weight_add) * pt_weight_mult\n",
    "                except:\n",
    "                    return sentinel\n",
    "            else:\n",
    "                return sentinel\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return sentinel\n",
    "\n",
    "    filled_col_name = f\"{uwt_col}_filled_from_pt\"\n",
    "    prepared_df[filled_col_name] = prepared_df.apply(fill_with_pt, axis=1)\n",
    "    prepared_df[filled_col_name + \"_flag\"] = prepared_df[filled_col_name].isin([999]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_pt_columns_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_pt',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_pt_columns_flag_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_pt_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_yb_pairs = [\n",
    "    (\"Best_Pos_BT_UWT\", \"Best_Pos_UWT_YB\"),\n",
    "    (\"Best_Pos_BT_PT\", \"Best_Pos_PT_YB\"),\n",
    "]\n",
    "\n",
    "for bt_col, yb_col in bt_yb_pairs:\n",
    "    def fill_with_yb(row):\n",
    "        val = row[bt_col]\n",
    "        yb_val = row[yb_col]\n",
    "\n",
    "        if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "            if pd.notna(yb_val) and yb_val not in [\"DNF\", \"DSQ\"]:\n",
    "                try:\n",
    "                    return float(yb_val)\n",
    "                except:\n",
    "                    return sentinel\n",
    "            else:\n",
    "                return sentinel\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return sentinel\n",
    "\n",
    "    filled_col_name = f\"{bt_col}_filled_from_yb\"\n",
    "    prepared_df[filled_col_name] = prepared_df.apply(fill_with_yb, axis=1)\n",
    "    prepared_df[filled_col_name + \"_flag\"] = prepared_df[filled_col_name].isin([999]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_yb_columns_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_yb',\n",
    " 'Best_Pos_BT_PT_filled_from_yb',                              \n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_yb_columns_flag_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_yb_flag',\n",
    " 'Best_Pos_BT_PT_filled_from_yb_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Scenarios logic worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of sentinel values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify relevant columns to check\n",
    "sentinel_cols = [col for col in prepared_df.columns if col.endswith('_sent') \n",
    "                 or col.endswith('_filled_from_pt') or col.endswith('_filled_from_yb')]\n",
    "\n",
    "# Count the number of sentinel values in each\n",
    "sentinel_counts = prepared_df[sentinel_cols].apply(lambda col: (col == sentinel).sum()).sort_values(ascending=False)\n",
    "\n",
    "print(\"Sentinel value counts per column:\")\n",
    "print(sentinel_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new filled columns aren't empty or completely filled with sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_cols = [col for col in prepared_df.columns if col.endswith('_filled_from_pt') or col.endswith('_filled_from_yb')]\n",
    "\n",
    "for col in filled_cols:\n",
    "    total = len(prepared_df)\n",
    "    sentinel_count = (prepared_df[col] == sentinel).sum()\n",
    "    null_count = prepared_df[col].isnull().sum()\n",
    "    unique_vals = prepared_df[col].nunique(dropna=True)\n",
    "\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Total rows: {total}\")\n",
    "    print(f\"  Sentinel count: {sentinel_count}\")\n",
    "    print(f\"  Null count: {null_count}\")\n",
    "    print(f\"  Unique non-null values: {unique_vals}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot-check the logic of fallback columns (e.g. Scenario 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original, fallback, and final filled values\n",
    "check_sample = prepared_df[\n",
    "    ['Best_Pos_BT_UWT', 'Best_Pos_BT_PT', 'Best_Pos_BT_UWT_filled_from_pt']\n",
    "].sample(10)\n",
    "\n",
    "print(check_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2012].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2023].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2024].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set year to start from 2012 as data from 2011 will include \"YB\" (Year Before) data which has no data filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = prepared_df[prepared_df['Year'] >= 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out DNF or DSQ from TDF_Pos\n",
    "prepared_df = prepared_df[~prepared_df['TDF_Pos'].isin(['DNF', 'DSQ'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out nulls from TDF_Pos\n",
    "prepared_df = prepared_df.dropna(subset=['TDF_Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TDF_Pos to numeric\n",
    "prepared_df['TDF_Pos'] = pd.to_numeric(prepared_df['TDF_Pos'])\n",
    "\n",
    "# 1 if TDF_Pos <= 20, else 0\n",
    "prepared_df['is_top20'] = (prepared_df['TDF_Pos'] <= 20).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features = ['Age', 'FC_Pos_YB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dict = {}\n",
    "\n",
    "# Add your static scenarios\n",
    "scenario_dict['null'] = {\n",
    "    'X': prepared_df[core_features + null_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "scenario_dict['sent'] = {\n",
    "    'X': prepared_df[core_features + sent_columns_list + sent_flag_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "scenario_dict['dnf_sent'] = {\n",
    "    'X': prepared_df[core_features + dnf_sent_columns_list + dnf_flag_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "# Define wider range of PT weight scenarios including no weight\n",
    "pt_weight_scenarios = [\n",
    "    {\"name\": \"filled_from_pt_no_weight\", \"add\": 0, \"mult\": 1.0},\n",
    "    {\"name\": \"filled_from_pt_low_weight\", \"add\": 1, \"mult\": 1.2},\n",
    "    {\"name\": \"filled_from_pt_medium_weight\", \"add\": 3, \"mult\": 1.5},\n",
    "    {\"name\": \"filled_from_pt_high_weight\", \"add\": 5, \"mult\": 2.0},\n",
    "    {\"name\": \"filled_from_pt_very_high_weight\", \"add\": 7, \"mult\": 2.5},\n",
    "]\n",
    "\n",
    "for pt_scenario in pt_weight_scenarios:\n",
    "    scenario_name = pt_scenario[\"name\"]\n",
    "    df_with_filled, filled_cols, flag_cols = generate_filled_from_pt_cols(\n",
    "        prepared_df,\n",
    "        pt_weight_add=pt_scenario[\"add\"],\n",
    "        pt_weight_mult=pt_scenario[\"mult\"]\n",
    "    )\n",
    "\n",
    "    scenario_dict[scenario_name] = {\n",
    "        \"X\": df_with_filled[core_features + filled_cols + flag_cols],\n",
    "        \"y\": df_with_filled[\"is_top20\"],\n",
    "        \"pt_add\": pt_scenario[\"add\"],\n",
    "        \"pt_mult\": pt_scenario[\"mult\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scenario_dict = {\n",
    "    'null': {\n",
    "        'X': prepared_df[core_features + null_columns_list],\n",
    "        'y': prepared_df['is_top20']\n",
    "    },\n",
    "    'sent': {\n",
    "        'X': prepared_df[core_features + sent_columns_list + sent_flag_columns_list],\n",
    "        'y': prepared_df['is_top20']\n",
    "    },\n",
    "    'dnf_sent': {\n",
    "        'X': prepared_df[core_features + dnf_sent_columns_list + dnf_flag_columns_list],\n",
    "        'y': prepared_df['is_top20']\n",
    "    },\n",
    "    'filled_from_pt': {\n",
    "        'X': prepared_df[core_features + filled_from_pt_columns_list + filled_from_pt_columns_flag_list],\n",
    "        'y': prepared_df['is_top20']\n",
    "    },\n",
    "    'filled_from_yb': {\n",
    "        'X': prepared_df[core_features + filled_from_yb_columns_list + filled_from_yb_columns_flag_list],\n",
    "        'y': prepared_df['is_top20']\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RandomForestClassifier as it seemed to perform best from initial tests (very strong recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    #('scaler', StandardScaler()), \n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for scenario_name, scenario_data in scenario_dict.items():\n",
    "    \n",
    "    pt_add = scenario_data.get(\"pt_add\")\n",
    "    pt_mult = scenario_data.get(\"pt_mult\")\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Scenario: {scenario_name} | PT add: {pt_add} | PT mult: {pt_mult}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    y_binary = scenario_data['y']\n",
    "\n",
    "    train_mask = (prepared_df['Year'] >= 2012) & (prepared_df['Year'] <= 2023)\n",
    "    test_mask = (prepared_df['Year'] == 2024)\n",
    "\n",
    "    X_train = scenario_data['X'].loc[train_mask]\n",
    "    y_train = y_binary.loc[train_mask]\n",
    "    X_test = scenario_data['X'].loc[test_mask]\n",
    "    y_test = y_binary.loc[test_mask]\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv_splitter, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    top20_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(\"Classification Report (Test Set - 2024):\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"AUC Score on Test Set: {roc_auc_score(y_test, top20_probs):.3f}\")\n",
    "\n",
    "    rf_model = best_model.named_steps['classifier']\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = scenario_data['X'].columns\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop Feature Importances:\")\n",
    "    print(feature_importance_df.head(30))\n",
    "\n",
    "    #plt.figure(figsize=(8, 5))\n",
    "    #plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    #plt.gca().invert_yaxis()\n",
    "    #plt.title(f\"Feature Importance - {scenario_name}\")\n",
    "    #plt.xlabel(\"Importance\")\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"Scenario\": scenario_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Recall_1\": recall_score(y_test, y_test_pred, pos_label=1),\n",
    "        \"F1_1\": f1_score(y_test, y_test_pred, pos_label=1),\n",
    "        \"AUC\": roc_auc_score(y_test, top20_probs)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "pd.DataFrame(results).sort_values(by='Recall_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
