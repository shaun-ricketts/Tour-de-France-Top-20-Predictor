{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Testing\n",
    "This notebook tests different strategies for handling missing and ambiguous race results (e.g., DNF/DSQ) in the Tour de France dataset. It compares multiple imputation and fallback scenarios to assess their impact on predictive performance.\n",
    "\n",
    "## Key Steps:\n",
    "- Defines five data handling scenarios using sentinel values, nulls, or fallback logic\n",
    "- Builds a classification pipeline to predict Top 20 finishes\n",
    "- Evaluates each scenario using cross-validation and test performance on 2024 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# visualisation tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn - Core Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# sklearn - Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Folder Path and Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root(start: Path, anchor_dirs=(\"src\", \"Data\")) -> Path:\n",
    "    \"\"\"\n",
    "    Walk up the directory tree until we find a folder that\n",
    "    contains all anchor_dirs (e.g. 'src' and 'Data').\n",
    "    \"\"\"\n",
    "    path = start.resolve()\n",
    "    for parent in [path] + list(path.parents):\n",
    "        if all((parent / d).is_dir() for d in anchor_dirs):\n",
    "            return parent\n",
    "    raise FileNotFoundError(\"Could not locate project root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the project root regardless of notebook depth\n",
    "project_root = find_project_root(Path.cwd())\n",
    "\n",
    "# ----- Code modules --------------------------------------------------\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import preprocess_tdf_data   # import data preproc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data folder: C:\\Users\\Shaun Ricketts\\Documents\\GitHub\\Tour-de-France-Top-20-Predictor\\Data\\Raw\n",
      "Processed data folder: C:\\Users\\Shaun Ricketts\\Documents\\GitHub\\Tour-de-France-Top-20-Predictor\\Data\\Processed\n"
     ]
    }
   ],
   "source": [
    "# ----- Data ----------------------------------------------------------\n",
    "raw_data_path = project_root / \"Data\" / \"Raw\"\n",
    "processed_data_path = project_root / \"Data\" / \"Processed\"\n",
    "print(\"Raw data folder:\", raw_data_path)\n",
    "print(\"Processed data folder:\", processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = pd.read_csv(processed_data_path / \"tdf_prepared_2011_2024.csv\",\n",
    "                         usecols = ['Rider_ID', 'Year', 'Age', 'TDF_Pos', 'Best_Pos_BT_UWT',\n",
    "                           'Best_Pos_BT_PT', 'Best_Pos_UWT_YB', 'Best_Pos_PT_YB', 'FC_Pos_YB', 'best_recent_tdf_result', \n",
    "                           'best_recent_other_gt_result', 'rode_giro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Nulls and DNFs (etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 1: Replace DNFs with Nulls\n",
    "- Scenario 2: Replace DNFs and Nulls with Sentinel (999)\n",
    "- Scenario 3: Replace DNFs with Sentinel and leave Nulls\n",
    "- Scenario 4: Replace nulls/DNFs in Best_UWT results with Best_PT results (with weight), if still null use sentinel\n",
    "- Scenario 5: Replace nulls/DNFs in Best_UWT & Best_PT with previous year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a value for the sentinel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down columns to only ones likely to use in final model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cols with \"DNF\" value (\"DNS\" in same col as \"DNF\")\n",
    "dnf_columns = (prepared_df == \"DNF\").any()[lambda x: x].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cols with nulls\n",
    "null_columns = (prepared_df.isnull()).any()[lambda x: x].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rider_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>TDF_Pos</th>\n",
       "      <th>Best_Pos_BT_UWT</th>\n",
       "      <th>Best_Pos_BT_PT</th>\n",
       "      <th>Best_Pos_UWT_YB</th>\n",
       "      <th>Best_Pos_PT_YB</th>\n",
       "      <th>FC_Pos_YB</th>\n",
       "      <th>best_recent_tdf_result</th>\n",
       "      <th>best_recent_other_gt_result</th>\n",
       "      <th>rode_giro</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>DNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21229</th>\n",
       "      <td>220860</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21230</th>\n",
       "      <td>229373</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21231</th>\n",
       "      <td>230418</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21232</th>\n",
       "      <td>231012</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21233</th>\n",
       "      <td>237784</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21234 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rider_ID  Year TDF_Pos Best_Pos_BT_UWT Best_Pos_BT_PT Best_Pos_UWT_YB  \\\n",
       "0             2  2011     NaN            67.0            NaN             NaN   \n",
       "1             3  2011     5.0             1.0            NaN             NaN   \n",
       "2             3  2012     NaN             NaN            NaN             1.0   \n",
       "3             3  2013     4.0             3.0            2.0             1.0   \n",
       "4             3  2014     DNF             1.0            NaN             3.0   \n",
       "...         ...   ...     ...             ...            ...             ...   \n",
       "21229    220860  2023     NaN             NaN            NaN             NaN   \n",
       "21230    229373  2024     NaN             NaN            NaN             NaN   \n",
       "21231    230418  2024     NaN             NaN            NaN             NaN   \n",
       "21232    231012  2024     NaN             NaN            NaN             NaN   \n",
       "21233    237784  2024     NaN             NaN            NaN             NaN   \n",
       "\n",
       "      Best_Pos_PT_YB  FC_Pos_YB  best_recent_tdf_result  \\\n",
       "0                NaN          1                     NaN   \n",
       "1                NaN          1                     1.0   \n",
       "2                NaN          2                     NaN   \n",
       "3                NaN         12                     5.0   \n",
       "4                2.0         13                     4.0   \n",
       "...              ...        ...                     ...   \n",
       "21229            NaN        500                     NaN   \n",
       "21230            NaN        499                     NaN   \n",
       "21231            NaN        499                     NaN   \n",
       "21232            NaN        499                     NaN   \n",
       "21233            NaN        499                     NaN   \n",
       "\n",
       "       best_recent_other_gt_result  rode_giro  Age  \n",
       "0                              NaN        NaN   40  \n",
       "1                              1.0        0.0   29  \n",
       "2                              NaN        NaN   30  \n",
       "3                              1.0        0.0   31  \n",
       "4                              1.0        0.0   32  \n",
       "...                            ...        ...  ...  \n",
       "21229                          NaN        NaN   19  \n",
       "21230                          NaN        NaN   19  \n",
       "21231                          NaN        NaN   20  \n",
       "21232                          NaN        NaN   20  \n",
       "21233                          NaN        NaN   19  \n",
       "\n",
       "[21234 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rider_ID', 'Year', 'TDF_Pos', 'Best_Pos_BT_UWT', 'Best_Pos_BT_PT',\n",
       "       'Best_Pos_UWT_YB', 'Best_Pos_PT_YB', 'FC_Pos_YB',\n",
       "       'best_recent_tdf_result', 'best_recent_other_gt_result', 'rode_giro',\n",
       "       'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"DNF\" with null and create _null indicator columns\n",
    "for col in dnf_columns:\n",
    "    prepared_df[col + \"_null\"] = prepared_df[col].replace(\"DNF\", np.nan)\n",
    "    prepared_df[col + \"_null\"] = prepared_df[col + \"_null\"].replace(\"DSQ\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List for outputted cols\n",
    "null_columns_list = [\n",
    " 'Best_Pos_BT_UWT_null',\n",
    " 'Best_Pos_BT_PT_null',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in null_columns:\n",
    "    prepared_df[col + \"_sent\"] = prepared_df[col].replace({\"DNF\": np.nan, \"DSQ\": np.nan})\n",
    "    prepared_df[col + '_sent_flag'] = prepared_df[col].isnull().astype(int)\n",
    "    prepared_df[col + '_sent'] = prepared_df[col + \"_sent\"].fillna(sentinel)\n",
    "    prepared_df[col + '_sent'] = prepared_df[col + '_sent'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_columns_list = [col for col in prepared_df.columns if col.endswith(\"_sent\")]\n",
    "sent_flag_columns_list = [col for col in prepared_df.columns if col.endswith(\"_sent_flag\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_columns_list = [\n",
    " 'Best_Pos_BT_UWT_sent',\n",
    " 'Best_Pos_BT_PT_sent',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_flag_columns_list = [\n",
    " 'Best_Pos_BT_UWT_sent_flag',\n",
    " 'Best_Pos_BT_PT_sent_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in dnf_columns:\n",
    "    prepared_df[col + \"_dnf_flag\"] = prepared_df[col].isin([\"DNF\", \"DSQ\"]).astype(int)  # Boolean indicator\n",
    "    prepared_df[col + \"_dnf_sent\"] = prepared_df[col].replace({\"DNF\": sentinel, \"DSQ\": sentinel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_flag_columns_list = [col for col in prepared_df.columns if col.endswith(\"_dnf_flag\")]\n",
    "dnf_sent_columns_list = [col for col in prepared_df.columns if col.endswith(\"_dnf_sent\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_sent_columns_list = [\n",
    " 'Best_Pos_BT_UWT_dnf_sent',\n",
    " 'Best_Pos_BT_PT_dnf_sent',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_flag_columns_list = [\n",
    " 'Best_Pos_BT_UWT_dnf_flag',\n",
    " 'Best_Pos_BT_PT_dnf_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a weight for use of pro-tour result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_weight_add = 3\n",
    "pt_weight_mult = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filled_from_pt_cols(df, pt_weight_add=3, pt_weight_mult=1.5):\n",
    "    uwt_pt_pairs = [\n",
    "        (\"Best_Pos_BT_UWT\", \"Best_Pos_BT_PT\"),\n",
    "        # add more if needed\n",
    "    ]\n",
    "    \n",
    "    filled_cols = []\n",
    "    flag_cols = []\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for uwt_col, pt_col in uwt_pt_pairs:\n",
    "        def fill_with_pt(row):\n",
    "            val = row[uwt_col]\n",
    "            pt_val = row[pt_col]\n",
    "\n",
    "            if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "                if pd.notna(pt_val) and pt_val not in [\"DNF\", \"DSQ\"]:\n",
    "                    try:\n",
    "                        return (float(pt_val) + pt_weight_add) * pt_weight_mult\n",
    "                    except:\n",
    "                        return 999  # sentinel\n",
    "                else:\n",
    "                    return 999\n",
    "            else:\n",
    "                try:\n",
    "                    return float(val)\n",
    "                except:\n",
    "                    return 999\n",
    "\n",
    "        filled_col_name = f\"{uwt_col}_filled_from_pt_add{pt_weight_add}_mult{pt_weight_mult}\"\n",
    "        flag_col_name = f\"{filled_col_name}_flag\"\n",
    "\n",
    "        df[filled_col_name] = df.apply(fill_with_pt, axis=1)\n",
    "        df[flag_col_name] = (df[filled_col_name] == 999).astype(int)\n",
    "\n",
    "        filled_cols.append(filled_col_name)\n",
    "        flag_cols.append(flag_col_name)\n",
    "\n",
    "    return df, filled_cols, flag_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uwt_pt_pairs = [\n",
    "    (\"Best_Pos_BT_UWT\", \"Best_Pos_BT_PT\"),\n",
    "    #(\"Best_Pos_AT_UWT_YB\", \"Best_Pos_AT_PT_YB\"),\n",
    "    #(\"Best_Pos_UWT_YB\", \"Best_Pos_PT_YB\"),\n",
    "]\n",
    "\n",
    "for uwt_col, pt_col in uwt_pt_pairs:\n",
    "    def fill_with_pt(row):\n",
    "        val = row[uwt_col]\n",
    "        pt_val = row[pt_col]\n",
    "\n",
    "        if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "            if pd.notna(pt_val) and pt_val not in [\"DNF\", \"DSQ\"]:\n",
    "                try:\n",
    "                    return (float(pt_val) + pt_weight_add) * pt_weight_mult\n",
    "                except:\n",
    "                    return sentinel\n",
    "            else:\n",
    "                return sentinel\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return sentinel\n",
    "\n",
    "    filled_col_name = f\"{uwt_col}_filled_from_pt\"\n",
    "    prepared_df[filled_col_name] = prepared_df.apply(fill_with_pt, axis=1)\n",
    "    prepared_df[filled_col_name + \"_flag\"] = prepared_df[filled_col_name].isin([999]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_pt_columns_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_pt',\n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_pt_columns_flag_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_pt_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_yb_pairs = [\n",
    "    (\"Best_Pos_BT_UWT\", \"Best_Pos_UWT_YB\"),\n",
    "    (\"Best_Pos_BT_PT\", \"Best_Pos_PT_YB\"),\n",
    "]\n",
    "\n",
    "for bt_col, yb_col in bt_yb_pairs:\n",
    "    def fill_with_yb(row):\n",
    "        val = row[bt_col]\n",
    "        yb_val = row[yb_col]\n",
    "\n",
    "        if pd.isna(val) or val in [\"DNF\", \"DSQ\"]:\n",
    "            if pd.notna(yb_val) and yb_val not in [\"DNF\", \"DSQ\"]:\n",
    "                try:\n",
    "                    return float(yb_val)\n",
    "                except:\n",
    "                    return sentinel\n",
    "            else:\n",
    "                return sentinel\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return sentinel\n",
    "\n",
    "    filled_col_name = f\"{bt_col}_filled_from_yb\"\n",
    "    prepared_df[filled_col_name] = prepared_df.apply(fill_with_yb, axis=1)\n",
    "    prepared_df[filled_col_name + \"_flag\"] = prepared_df[filled_col_name].isin([999]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_yb_columns_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_yb',\n",
    " 'Best_Pos_BT_PT_filled_from_yb',                              \n",
    " 'best_recent_tdf_result_sent',\n",
    " 'best_recent_other_gt_result_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_from_yb_columns_flag_list = [\n",
    " 'Best_Pos_BT_UWT_filled_from_yb_flag',\n",
    " 'Best_Pos_BT_PT_filled_from_yb_flag',\n",
    " 'best_recent_tdf_result_sent_flag',\n",
    " 'best_recent_other_gt_result_sent_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Scenarios logic worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of sentinel values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel value counts per column:\n",
      "best_recent_tdf_result_sent         19427\n",
      "best_recent_other_gt_result_sent    19425\n",
      "TDF_Pos_sent                        19068\n",
      "rode_giro_sent                      18608\n",
      "Best_Pos_UWT_YB_sent                13477\n",
      "Best_Pos_BT_UWT_sent                13094\n",
      "Best_Pos_BT_UWT_filled_from_yb      11350\n",
      "Best_Pos_PT_YB_sent                  9685\n",
      "Best_Pos_BT_PT_sent                  8756\n",
      "Best_Pos_BT_UWT_filled_from_pt       5919\n",
      "Best_Pos_BT_PT_filled_from_yb        5042\n",
      "Best_Pos_BT_PT_dnf_sent              1981\n",
      "Best_Pos_PT_YB_dnf_sent              1031\n",
      "Best_Pos_BT_UWT_dnf_sent             1009\n",
      "Best_Pos_UWT_YB_dnf_sent              678\n",
      "TDF_Pos_dnf_sent                      460\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify relevant columns to check\n",
    "sentinel_cols = [col for col in prepared_df.columns if col.endswith('_sent') \n",
    "                 or col.endswith('_filled_from_pt') or col.endswith('_filled_from_yb')]\n",
    "\n",
    "# Count the number of sentinel values in each\n",
    "sentinel_counts = prepared_df[sentinel_cols].apply(lambda col: (col == sentinel).sum()).sort_values(ascending=False)\n",
    "\n",
    "print(\"Sentinel value counts per column:\")\n",
    "print(sentinel_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new filled columns aren't empty or completely filled with sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Pos_BT_UWT_filled_from_pt:\n",
      "  Total rows: 21234\n",
      "  Sentinel count: 5919\n",
      "  Null count: 0\n",
      "  Unique non-null values: 281\n",
      "\n",
      "Best_Pos_BT_UWT_filled_from_yb:\n",
      "  Total rows: 21234\n",
      "  Sentinel count: 11350\n",
      "  Null count: 0\n",
      "  Unique non-null values: 172\n",
      "\n",
      "Best_Pos_BT_PT_filled_from_yb:\n",
      "  Total rows: 21234\n",
      "  Sentinel count: 5042\n",
      "  Null count: 0\n",
      "  Unique non-null values: 168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_cols = [col for col in prepared_df.columns if col.endswith('_filled_from_pt') or col.endswith('_filled_from_yb')]\n",
    "\n",
    "for col in filled_cols:\n",
    "    total = len(prepared_df)\n",
    "    sentinel_count = (prepared_df[col] == sentinel).sum()\n",
    "    null_count = prepared_df[col].isnull().sum()\n",
    "    unique_vals = prepared_df[col].nunique(dropna=True)\n",
    "\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Total rows: {total}\")\n",
    "    print(f\"  Sentinel count: {sentinel_count}\")\n",
    "    print(f\"  Null count: {null_count}\")\n",
    "    print(f\"  Unique non-null values: {unique_vals}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot-check the logic of fallback columns (e.g. Scenario 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Best_Pos_BT_UWT Best_Pos_BT_PT  Best_Pos_BT_UWT_filled_from_pt\n",
      "20054            34.0           29.0                            34.0\n",
      "15118             NaN           84.0                           130.5\n",
      "11438             NaN            NaN                           999.0\n",
      "21108             NaN          120.0                           184.5\n",
      "3430             36.0            NaN                            36.0\n",
      "3021              NaN          105.0                           162.0\n",
      "19022             NaN           58.0                            91.5\n",
      "426              63.0           20.0                            63.0\n",
      "1899              NaN           40.0                            64.5\n",
      "13416             NaN            NaN                           999.0\n"
     ]
    }
   ],
   "source": [
    "# Compare original, fallback, and final filled values\n",
    "check_sample = prepared_df[\n",
    "    ['Best_Pos_BT_UWT', 'Best_Pos_BT_PT', 'Best_Pos_BT_UWT_filled_from_pt']\n",
    "].sample(10)\n",
    "\n",
    "print(check_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1486, 49)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2012].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661, 49)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2023].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1629, 49)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df[prepared_df[\"Year\"]==2024].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set year to start from 2012 as data from 2011 will include \"YB\" (Year Before) data which has no data filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = prepared_df[prepared_df['Year'] >= 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out DNF or DSQ from TDF_Pos\n",
    "prepared_df = prepared_df[~prepared_df['TDF_Pos'].isin(['DNF', 'DSQ'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out nulls from TDF_Pos\n",
    "prepared_df = prepared_df.dropna(subset=['TDF_Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TDF_Pos to numeric\n",
    "prepared_df['TDF_Pos'] = pd.to_numeric(prepared_df['TDF_Pos'])\n",
    "\n",
    "# 1 if TDF_Pos <= 20, else 0\n",
    "prepared_df['is_top20'] = (prepared_df['TDF_Pos'] <= 20).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features = ['Age', 'FC_Pos_YB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dict = {}\n",
    "\n",
    "# Add your static scenarios\n",
    "scenario_dict['null'] = {\n",
    "    'X': prepared_df[core_features + null_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "scenario_dict['sent'] = {\n",
    "    'X': prepared_df[core_features + sent_columns_list + sent_flag_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "scenario_dict['dnf_sent'] = {\n",
    "    'X': prepared_df[core_features + dnf_sent_columns_list + dnf_flag_columns_list],\n",
    "    'y': prepared_df['is_top20']\n",
    "}\n",
    "\n",
    "# Define wider range of PT weight scenarios including no weight\n",
    "pt_weight_scenarios = [\n",
    "    {\"name\": \"filled_from_pt_no_weight\", \"add\": 0, \"mult\": 1.0},\n",
    "    {\"name\": \"filled_from_pt_low_weight\", \"add\": 1, \"mult\": 1.2},\n",
    "    {\"name\": \"filled_from_pt_medium_weight\", \"add\": 3, \"mult\": 1.5},\n",
    "    {\"name\": \"filled_from_pt_high_weight\", \"add\": 5, \"mult\": 2.0},\n",
    "    {\"name\": \"filled_from_pt_very_high_weight\", \"add\": 7, \"mult\": 2.5},\n",
    "]\n",
    "\n",
    "for pt_scenario in pt_weight_scenarios:\n",
    "    scenario_name = pt_scenario[\"name\"]\n",
    "    df_with_filled, filled_cols, flag_cols = generate_filled_from_pt_cols(\n",
    "        prepared_df,\n",
    "        pt_weight_add=pt_scenario[\"add\"],\n",
    "        pt_weight_mult=pt_scenario[\"mult\"]\n",
    "    )\n",
    "\n",
    "    scenario_dict[scenario_name] = {\n",
    "        \"X\": df_with_filled[core_features + filled_cols + flag_cols],\n",
    "        \"y\": df_with_filled[\"is_top20\"],\n",
    "        \"pt_add\": pt_scenario[\"add\"],\n",
    "        \"pt_mult\": pt_scenario[\"mult\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RandomForestClassifier as it seemed to perform best from initial tests (very strong recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Scenario: null | PT add: None | PT mult: None\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       121\n",
      "           1       0.61      0.55      0.58        20\n",
      "\n",
      "    accuracy                           0.89       141\n",
      "   macro avg       0.77      0.75      0.76       141\n",
      "weighted avg       0.88      0.89      0.88       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[114   7]\n",
      " [  9  11]]\n",
      "AUC Score on Test Set: 0.896\n",
      "\n",
      "Top Feature Importances:\n",
      "                Feature  Importance\n",
      "2  Best_Pos_BT_UWT_null    0.499411\n",
      "1             FC_Pos_YB    0.301404\n",
      "3   Best_Pos_BT_PT_null    0.115888\n",
      "0                   Age    0.083298\n",
      "\n",
      "==============================\n",
      "Scenario: sent | PT add: None | PT mult: None\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       121\n",
      "           1       0.78      0.70      0.74        20\n",
      "\n",
      "    accuracy                           0.93       141\n",
      "   macro avg       0.86      0.83      0.85       141\n",
      "weighted avg       0.93      0.93      0.93       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117   4]\n",
      " [  6  14]]\n",
      "AUC Score on Test Set: 0.962\n",
      "\n",
      "Top Feature Importances:\n",
      "                                 Feature  Importance\n",
      "2                   Best_Pos_BT_UWT_sent    0.344280\n",
      "4            best_recent_tdf_result_sent    0.196647\n",
      "5       best_recent_other_gt_result_sent    0.182339\n",
      "1                              FC_Pos_YB    0.140570\n",
      "0                                    Age    0.058300\n",
      "3                    Best_Pos_BT_PT_sent    0.050757\n",
      "7               Best_Pos_BT_PT_sent_flag    0.010317\n",
      "8       best_recent_tdf_result_sent_flag    0.008066\n",
      "9  best_recent_other_gt_result_sent_flag    0.007759\n",
      "6              Best_Pos_BT_UWT_sent_flag    0.000966\n",
      "\n",
      "==============================\n",
      "Scenario: dnf_sent | PT add: None | PT mult: None\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       121\n",
      "           1       0.70      0.70      0.70        20\n",
      "\n",
      "    accuracy                           0.91       141\n",
      "   macro avg       0.83      0.83      0.83       141\n",
      "weighted avg       0.91      0.91      0.91       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[115   6]\n",
      " [  6  14]]\n",
      "AUC Score on Test Set: 0.967\n",
      "\n",
      "Top Feature Importances:\n",
      "                                 Feature  Importance\n",
      "2               Best_Pos_BT_UWT_dnf_sent    0.353708\n",
      "4            best_recent_tdf_result_sent    0.205429\n",
      "5       best_recent_other_gt_result_sent    0.174501\n",
      "1                              FC_Pos_YB    0.136167\n",
      "0                                    Age    0.056162\n",
      "3                Best_Pos_BT_PT_dnf_sent    0.053724\n",
      "8       best_recent_tdf_result_sent_flag    0.008448\n",
      "9  best_recent_other_gt_result_sent_flag    0.006656\n",
      "6               Best_Pos_BT_UWT_dnf_flag    0.002797\n",
      "7                Best_Pos_BT_PT_dnf_flag    0.002407\n",
      "\n",
      "==============================\n",
      "Scenario: filled_from_pt_no_weight | PT add: 0 | PT mult: 1.0\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       121\n",
      "           1       0.48      0.70      0.57        20\n",
      "\n",
      "    accuracy                           0.85       141\n",
      "   macro avg       0.71      0.79      0.74       141\n",
      "weighted avg       0.88      0.85      0.86       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[106  15]\n",
      " [  6  14]]\n",
      "AUC Score on Test Set: 0.913\n",
      "\n",
      "Top Feature Importances:\n",
      "                                            Feature  Importance\n",
      "2       Best_Pos_BT_UWT_filled_from_pt_add0_mult1.0    0.556862\n",
      "1                                         FC_Pos_YB    0.346236\n",
      "0                                               Age    0.091805\n",
      "3  Best_Pos_BT_UWT_filled_from_pt_add0_mult1.0_flag    0.005097\n",
      "\n",
      "==============================\n",
      "Scenario: filled_from_pt_low_weight | PT add: 1 | PT mult: 1.2\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       121\n",
      "           1       0.52      0.70      0.60        20\n",
      "\n",
      "    accuracy                           0.87       141\n",
      "   macro avg       0.73      0.80      0.76       141\n",
      "weighted avg       0.89      0.87      0.87       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  13]\n",
      " [  6  14]]\n",
      "AUC Score on Test Set: 0.912\n",
      "\n",
      "Top Feature Importances:\n",
      "                                            Feature  Importance\n",
      "2       Best_Pos_BT_UWT_filled_from_pt_add1_mult1.2    0.583773\n",
      "1                                         FC_Pos_YB    0.323953\n",
      "0                                               Age    0.086761\n",
      "3  Best_Pos_BT_UWT_filled_from_pt_add1_mult1.2_flag    0.005513\n",
      "\n",
      "==============================\n",
      "Scenario: filled_from_pt_medium_weight | PT add: 3 | PT mult: 1.5\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       121\n",
      "           1       0.48      0.70      0.57        20\n",
      "\n",
      "    accuracy                           0.85       141\n",
      "   macro avg       0.71      0.79      0.74       141\n",
      "weighted avg       0.88      0.85      0.86       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[106  15]\n",
      " [  6  14]]\n",
      "AUC Score on Test Set: 0.910\n",
      "\n",
      "Top Feature Importances:\n",
      "                                            Feature  Importance\n",
      "2       Best_Pos_BT_UWT_filled_from_pt_add3_mult1.5    0.582594\n",
      "1                                         FC_Pos_YB    0.322383\n",
      "0                                               Age    0.090295\n",
      "3  Best_Pos_BT_UWT_filled_from_pt_add3_mult1.5_flag    0.004728\n",
      "\n",
      "==============================\n",
      "Scenario: filled_from_pt_high_weight | PT add: 5 | PT mult: 2.0\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       121\n",
      "           1       0.50      0.65      0.57        20\n",
      "\n",
      "    accuracy                           0.86       141\n",
      "   macro avg       0.72      0.77      0.74       141\n",
      "weighted avg       0.88      0.86      0.87       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  13]\n",
      " [  7  13]]\n",
      "AUC Score on Test Set: 0.921\n",
      "\n",
      "Top Feature Importances:\n",
      "                                            Feature  Importance\n",
      "2       Best_Pos_BT_UWT_filled_from_pt_add5_mult2.0    0.584235\n",
      "1                                         FC_Pos_YB    0.321410\n",
      "0                                               Age    0.089244\n",
      "3  Best_Pos_BT_UWT_filled_from_pt_add5_mult2.0_flag    0.005110\n",
      "\n",
      "==============================\n",
      "Scenario: filled_from_pt_very_high_weight | PT add: 7 | PT mult: 2.5\n",
      "==============================\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Classification Report (Test Set - 2024):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       121\n",
      "           1       0.50      0.65      0.57        20\n",
      "\n",
      "    accuracy                           0.86       141\n",
      "   macro avg       0.72      0.77      0.74       141\n",
      "weighted avg       0.88      0.86      0.87       141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  13]\n",
      " [  7  13]]\n",
      "AUC Score on Test Set: 0.909\n",
      "\n",
      "Top Feature Importances:\n",
      "                                            Feature  Importance\n",
      "2       Best_Pos_BT_UWT_filled_from_pt_add7_mult2.5    0.589863\n",
      "1                                         FC_Pos_YB    0.315708\n",
      "0                                               Age    0.089507\n",
      "3  Best_Pos_BT_UWT_filled_from_pt_add7_mult2.5_flag    0.004921\n"
     ]
    }
   ],
   "source": [
    "cv_splitter = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    #('scaler', StandardScaler()), \n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for scenario_name, scenario_data in scenario_dict.items():\n",
    "    \n",
    "    pt_add = scenario_data.get(\"pt_add\")\n",
    "    pt_mult = scenario_data.get(\"pt_mult\")\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Scenario: {scenario_name} | PT add: {pt_add} | PT mult: {pt_mult}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    y_binary = scenario_data['y']\n",
    "\n",
    "    train_mask = (prepared_df['Year'] >= 2012) & (prepared_df['Year'] <= 2023)\n",
    "    test_mask = (prepared_df['Year'] == 2024)\n",
    "\n",
    "    X_train = scenario_data['X'].loc[train_mask]\n",
    "    y_train = y_binary.loc[train_mask]\n",
    "    X_test = scenario_data['X'].loc[test_mask]\n",
    "    y_test = y_binary.loc[test_mask]\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv_splitter, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    top20_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(\"Classification Report (Test Set - 2024):\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"AUC Score on Test Set: {roc_auc_score(y_test, top20_probs):.3f}\")\n",
    "\n",
    "    rf_model = best_model.named_steps['classifier']\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = scenario_data['X'].columns\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop Feature Importances:\")\n",
    "    print(feature_importance_df.head(30))\n",
    "\n",
    "    #plt.figure(figsize=(8, 5))\n",
    "    #plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    #plt.gca().invert_yaxis()\n",
    "    #plt.title(f\"Feature Importance - {scenario_name}\")\n",
    "    #plt.xlabel(\"Importance\")\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"Scenario\": scenario_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Recall_1\": recall_score(y_test, y_test_pred, pos_label=1),\n",
    "        \"F1_1\": f1_score(y_test, y_test_pred, pos_label=1),\n",
    "        \"AUC\": roc_auc_score(y_test, top20_probs)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sent</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.961983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dnf_sent</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.966529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filled_from_pt_no_weight</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.913223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filled_from_pt_low_weight</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.911570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>filled_from_pt_medium_weight</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.909917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>filled_from_pt_high_weight</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.921074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>filled_from_pt_very_high_weight</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.896281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Scenario  Accuracy  Recall_1      F1_1       AUC\n",
       "1                             sent  0.929078      0.70  0.736842  0.961983\n",
       "2                         dnf_sent  0.914894      0.70  0.700000  0.966529\n",
       "3         filled_from_pt_no_weight  0.851064      0.70  0.571429  0.913223\n",
       "4        filled_from_pt_low_weight  0.865248      0.70  0.595745  0.911570\n",
       "5     filled_from_pt_medium_weight  0.851064      0.70  0.571429  0.909917\n",
       "6       filled_from_pt_high_weight  0.858156      0.65  0.565217  0.921074\n",
       "7  filled_from_pt_very_high_weight  0.858156      0.65  0.565217  0.909091\n",
       "0                             null  0.886525      0.55  0.578947  0.896281"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of results\n",
    "pd.DataFrame(results).sort_values(by='Recall_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
